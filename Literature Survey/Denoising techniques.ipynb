{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOV/NSB397jFktczmivBmGG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JgIuiDegbD_r"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["##Wiener Filtering\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"-DSYOzDKbGff"}},{"cell_type":"markdown","source":["The main aim of this technique is gather the statistical information about data and then estimate true noise/clean noise from observing the input.\n","1.   y(t) = x(t) + n(t) \\\\\n","assume y(t) is the input sound. \\\\\n","x(t) is the clean sound \\\\\n","n(t) is the noise\n","2.   the input which is in time domain is converted into frequency domain using techniques like Fast Fourir Transform (FFT)\n","3.   Powe spectral density (PSD) is estimated of both noise input and clean sound.\n","4.   Wiener filter is desinged to reduce Mean squared error between the true sound and the estimated signal. \\\\\n","H(f) = X(f) / (X(f) + N(f)) \\\\\n","H(f) is the frequency-domain representation of wiener filter \\\\\n","X(f) is the PSD of true sound \\\\\n","N(f) is the PSD of noise\n","5.   Estimated true sound X(f) is obtained by multiplying estimated noise N(f) with wiener filter H(f)\n","6.   Inverse fourier transform (IFFT) is performed to convert the estimated true sound back into time domain\n","7. the output of IFFT, x(t) is the denoised sound\n","\n","(paper - Consistent Wiener Filtering for Audio Source Separation)"],"metadata":{"id":"IjxrHKP4pVIR"}},{"cell_type":"markdown","source":["##Spectral subtraction\n","\n"],"metadata":{"id":"Q6Qk064NsP4w"}},{"cell_type":"markdown","source":["It aims to calculate power spectral density (PSD) of noise and then substract it from the input sound.\n","\n","1.   Short-time fourier transform (STFT) is used to convert input sound from time domain to frequncy domain\n","2.   To calculate PSD of noise, first few frames of audio is selected (with assumption that no important info is present in these frames) then average or smoothed version of these frames is considered as estimation of noise PSD\n","3. now spectral subtraction is performed,\n","clean sound PSD = noisy input PSD - Noise PSD\n","4. perform inverse STFT to convert clean sound PSD to time domain\n","5. then overlap-add is performed to add the frames into continous clean audio sound.\n","\n","Disadvantages : sensitivity to errors in noise estimation, inability to handle non-stationary noise \\\\\n","\n","(paper - Heart sound classification based on scaled spectrogram and tensor decomposition)"],"metadata":{"id":"nkKWIiva3e5N"}},{"cell_type":"markdown","source":["## Principal Component Analysis (PCA)"],"metadata":{"id":"-UOe_B3Bcz0i"}},{"cell_type":"markdown","source":["PCA is not a common method for this purpose. both noisy sound input and clean sound is required to test PCA\n","\n","1.   at first, the audio is converted into frequency domian by STFT\n","2.   then PCA is applied on training part to get principal componenets which is direction of maximum variance\n","3.   feature projection takes place where both noisy and clean audio samples is projected onto reduced-dimensional subspace after calculating its principal components\n","4.   in reduced dimensional subspace, denoising is done. one common approach is thresholding.\n","5.   then its converted back to original space by performing inverse PCA\n","6.   inverse STFT is done to convert frequency domain to time domain\n","\n","disadvantage : when noise is complex or non-stationary \\\\\n","but can be used as preprocessing step before other denoising techniques to improve the results \\\\\n","(paper - An Improved Wavelet Denoising Algorithm Based on Principal Component Analysis)"],"metadata":{"id":"dapuxjPnc2UX"}},{"cell_type":"markdown","source":["## Wavelet Transformation"],"metadata":{"id":"yvZOywvDfzNc"}},{"cell_type":"markdown","source":["1.   wavelet tranform is done on the input sound (PCG) to decompose it into different frequenct components. wavelet transform helps to represent signal in both frquency and time domain\n","2.   after decomposition, each frequency composition is analysed. then thresholding techniques are applied on each wavelet coefficient to remove/shrink the coefficients below certain threshold (attenuate noise while preserving the true sound)(with the assumption that noise often appears at small-amplitude coefficients, while important signal occurs at large components)\n","3. decomposed wavelet compositions are combined by performing inverse wavelet transform to get denoised PCG\n","4. threshold levels are tuned to obtain desired level of clean audio sounds\n","\n","it allows for a multi-resolution analysis of the signal, which means that it can capture both high-frequency and low-frequency components of the signal and noise so its effective\n","\n","(paper - Denoising of Fetal Phonocardiogram Signal by Wavelet Transformation)"],"metadata":{"id":"BzaZQh_ghbzr"}},{"cell_type":"markdown","source":["## Empirical Mode Decomposition (EMD)"],"metadata":{"id":"fomy3lpPjwip"}},{"cell_type":"markdown","source":["particularly used for analysing non-linear and non-stationary data. main idea to decompose the signal to main sets called Intrinsic Mode Functions (IMFs) and then capture different scales of variation wrt these IMFs\n","\n","\n","\n","1.   EMD is performed on input sound to decompose it into IMFs\n","2.   IMFs are analysed to find out which out it may contain noise (noisy IMFs exhibit high0frequency and random fluctuations.\n","3.   then thresholding is applied on those noisy components to remove the noise\n","4.   IMFs are combined to get denoised audio\n","5.   quality assessment is done to ensure important features of signal are not removed and also noise is removed\n","\n","can be used on non-stationary and complex data\n","\n","(paper - NOISE FILTERING USING EMPIRICAL MODE DECOMPOSITION)"],"metadata":{"id":"otJ3npeLk-6T"}},{"cell_type":"markdown","source":["## Variational Decomposition Mode"],"metadata":{"id":"LXr7Zx7RX50Z"}},{"cell_type":"markdown","source":["\"Intrinsic Mode Functions (IMFs) are the simple oscillatory functions obtained from the decomposing a signal. Each IMF captures a specific oscillatory mode present in the original data signal. When these IMFs are added together, along with the residue, they reconstruct the original data signal.\" (https://www.collimator.ai/reference-guides/what-is-empirical-mode-decomposition#:~:text=The%20Empirical%20Mode%20Decomposition%20process,in%20the%20original%20data%20signal.)\n","\n","VDM\n","1. Similar to EDM\n","2. main signal is decomposed into multiple parts called IMFs. In the IMFs, number of local extrema and zero crossings differ at most by 1\n","3. Hilbert transformation is used in the decompostion of the IMFs\n","4. \"VDM behaves like a Wiener Filter: It is like a low-narrowband filter that only passes a range of frequencies around a low center frequency. The central frequency w is nearly 0. Because of that we have a low Variation from the center frequency. Minimize bandwidth across center frequency for each mode. So we get Modes with a minimal Bandwidth. But the Sum of all modes must be the original Signal.\"\n","4. main parameter of VDM is K (number of IMFs)\n","5. steps:\n","*   calculate K value\n","    1. if K is too small then some infomation in the main signal may get lost\n","    2. if K is too big then IMFs may contain repeated infomation because central frequency of adjacent IMF will be similar\n","*   decompose main signal into K number of IMFs\n","    1. decomposed IMFs frequencies are from low to high\n","*   Energy analysis\n","    1. frequency spectrum is concentrated on the lower-order modes so signal energy is very large at the low-order components.\n","    2. signal Energy starts also from strong to weak, because the energy based on signal and noise behaves differently in the IMFs\n","    3. Search the point where the low-order energy drops rapidly. It is marked as the signal and noise boundary point\n","*   wavelet thresholding\n","    1. after boundary point is identified, that particular IMF is selected then the selected IMF is passed through threshold function to get denoised signal\n","\n","\n","\n","limitation :\n","1. number of modes (frequency components) are unknown in real signal so cannot give exact number to the parameter\n","2. when 2 mode frequencies are too close, VMD fails to differentiate them\n","3. time consuming and highly depends on parameter initialization"],"metadata":{"id":"IalhXXB7X-rm"}},{"cell_type":"markdown","source":["## Why Deep Learning?"],"metadata":{"id":"NljqVfGbO2dD"}},{"cell_type":"markdown","source":["\n","\n","*   Existing methods like wavelets, EMD, etc. are data-dependent, rely on handcrafted features, and have several tuning parameters. Deep learning methods can learn features directly from the data in an end-to-end manner.\n","*   Earlier methods are often computationally intensive and time-consuming, not suitable for real-time denoising needed in mobile cardiac screening applications.\n","\n","\n","(Paper:  A Robust Deep Learning Framework for\n","Real-Time Denoising of Heart Sound)\n"],"metadata":{"id":"aEWpiSvQO_i5"}},{"cell_type":"markdown","source":["*   Existing methods like wavelets, empirical mode decomposition have limitations like dependence on handcrafted features, thresholds, subjectivity\n","\n","(Paper: A GAN Based Heart Sound Denoising Model)"],"metadata":{"id":"uu-p6Dh-PsCe"}},{"cell_type":"code","source":[],"metadata":{"id":"ZOJrAY1VmQJz"},"execution_count":null,"outputs":[]}]}